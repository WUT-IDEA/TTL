# Implement for 
# Enhancing RNN based OCR by Transductive Transfer Learning from Text to Images
- AAAI 2018, student abstract
- Author: He Yang, Yuan Jingling, Li Lin(corresponding: cathylilin@whut.edu.cn)
- Company: Wuhan University of Technology


Limited to pages, more details involving our approach are displayed below.
Code based on:
1) Ocropus-github
2) editdistance
3) tensorflow+keras

Dataset:
generated by  Ocropus-github. We have overwrited its code, using multi-processing to acceleration its effeciency.

Hypothesis:
1.Images are a counterpart in higher dimension of corresponding text.
2.There are considerable papers related to OCR are trying to use text to improve the accuracy of OCR systems.

The common relationship between text and its images are CHARACTER SEQUENTIAL RELATIONSHIP (CSR for short).
Whats's the character sequential relationship? For instance, what is '?' for 'learnin?'? Letter 'g' might be the best choice. This is the CSR of text. And we think this relationship are transferable from text to images.
In addition, owing to the merit of RNNs' training on text over images, learning CSR from images is harder than learning from text.
In sum, transferring CSR from text to images sounds pretty good.


Basic Model (RNN+CTC based model, proposed in [1]):
a layer of RNN with LSTM block + a layer of Full connected Network with softmax activation + CTC
This is the gist of OCR model proposed in [1]. More advanced networks can be added to enhance this model's performance. But we choose transductive transfer learning [2] to do so.


Problems:
Delay on accuracy
A typical phenomenon of this type of OCR model: there is a long period before accuracy's rapid climbing. And we aim to accelerate this phrase.
Training of basic model[singel.png]

Underfitting on small dataset
When this model is trained on a small dataset, its accuracy fluctuate round a low level. It is imperative to avoid underfitting.
The Brief Architecture of Our Approach[.png]

Our approach:
Given our hypothesis 1,2 and problems above, we utilize transductive transfer learning to TRANSFER the CSR of text to OCR model.
Step 1: train a text RNN generator, but its inputs and outputs are same. -- get CSR
Step 2: extend probability matrix of the same size of images. And then train these extended matrix and images on RNN networks. -- transfer CSR from text to matrix, and finally to RNN networks
Step 3: transfer pre-trained RNN networks in Step 2 to RNN+CTC based model. -- modify OCR model with images and pre-planted CSR

Results:
1. Acceleration of training phase.
For 1) training RNN generator cost little time and 2) there being no time-consuming CTC computation in Step 2, it will save much time. (In my environment, it saved us 20%~30% time)
2. Avoiding underfitting in a small dataset.
Pre-training in Step 2 cast the model nearer to the global optimum, avoiding lots of local traps.

Reference:
[1] Breuel, T. M., Ul-Hasan, A., Al-Azawi, M. A., & Shafait, F. (2013, August). High-performance OCR for printed English and Fraktur using LSTM networks. In Document Analysis and
Recognition (ICDAR), 2013 12th International Conference on (pp.683-687). IEEE.
[2] Pan, S. J., & Yang, Q. (2010). A survey on transfer learning. IEEE Transactions on knowledge and data engineering, 22(10), 1345-1359.

run main.py for the whole approach
*Due to SGD(rms), model's training is likely to fall into local optimum(you can expand model'dataset or add more network to address this problem directly)--its accuracy might remain quite low(below 10%); but sometimes model also get nice result(showed in our paper). But TTL mode, namely our approach, can avoid this problem and accelerate training.

Pls, waiting for our further search. More details will be showed in the future...
Thanks